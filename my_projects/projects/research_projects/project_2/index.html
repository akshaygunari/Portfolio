<!doctype html>
<html lang="en">
<head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="shortcut icon" type="image/png" href="../img/AK Icon.png" />
    <meta property="og:image" content="../img/AK Icon.png">
    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="../css/pensive.css">
<!--    style csss-->
    <link rel="stylesheet" href="../css/style.css">
<!--    font awesome cdn-->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

    <title>AK Blogs</title>
</head>
<body>
<!--navbar -->
<nav class="navbar navbar-expand-lg navbar-light bg-light shadow-sm">
    <a class="navbar-brand" href="..\..\..\my_projects_main_page.html">
        <i class="fa fa-magic" aria-hidden="true"></i>
        AK Blogs</a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse" id="navbarSupportedContent">
        <ul class="navbar-nav ml-auto">
            <li class="nav-item active">
                <a class="nav-link btn btn-primary text-light" href="..\..\..\my_projects_main_page.html">Projects Main Page<span class="sr-only">(current)</span></a>
            </li>
            <!-- <li class="nav-item">
                <a class="nav-link" href="#">Demos</a>
            </li>
            <li class="nav-item dropdown">
                <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    Pages
                </a>
                <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown">
                    <a class="dropdown-item" href="#">Action</a>
                    <a class="dropdown-item" href="#">Another action</a>
                    <div class="dropdown-divider"></div>
                    <a class="dropdown-item" href="#">Something else here</a>
                </div>
            </li> -->
            <!-- <li class="nav-item">
                <a class="nav-link" href="..\..\..\Main Page.html" aria-disabled="true">_AK_ Blogs</a>
            </li> -->
            <li class="nav-item">
                <a class="nav-link btn btn-primary text-light" href="..\..\..\..\index.html" aria-disabled="true">Akshayhumar Gunari</a>
            </li>
        </ul>
    </div>
</nav>
<!--end navbar-->

<!--first-section-->
<div class="first-section">
    <div class="container" >
        <div class="row justify-content-center">
            <div class="col-md-9 ">
                <h1 class="h2" style="text-align: center;">Progressive Clustering: An Unsupervised Approach Towards Continual Knowledge Acquisition of Incremental Data</h1>
                <div class="user d-flex align-items-start justify-content-between bg-light p-4 rounded">
                    <div class="d-flex align-items-start">
                        <img src="../img/AK.JPG" class="img-fluid rounded-circle" alt="">
                        <div class="d-block">
                            <span class="d-block">by <a class="h6" href="..\..\..\..\index.html">Akshayhumar Gunari</a></span>
                            <span class="d-block text-muted">28th December 2022</span>
                        </div>
                    </div>
                    <span class="badge badge-light-primary"><i class="fa fa-heart" aria-hidden="true"></i> 1</span>
                </div>
                <!--//blog section-->
                <div class="blog-section">
                    <img src="./images/reu_logo.png" class="bounce-little img-fluid shadow-sm rounded " alt="">
                    <br><br>
                    <h1 class="h">Data Acquisition in Real World</h1>
                    <p class="lead mt-3" style="text-align: justify;">
                        In this work, we propose a categorization strategy to handle
						the incremental nature of data by identifying concepts of drift in
						the data stream. In the world of digitalization, the total amount of data
						created, captured, copied, and consumed is increasing rapidly, reaching
						a few zettabytes. Various fields of data mining and machine learning
						applications involve clustering as their principal component, considering
						the non-incremental nature of the data. However, many real-world
						machine learning algorithms need to adapt to this ever-growing global
						data sphere to continually learn new patterns. In addition, the model
						needs to be acquainted with the continuous change in the distribution of
						the input data. Towards this, we propose a clustering algorithm termed
						as Progressive Clustering to foresee the phenomenon of increase in data
						and sustain it until the pattern of the data changes considerably. We
						demonstrate the results of our clustering algorithm by simulating various
						instances of the incremental nature of the data in the form of a
						data stream. We demonstrate the results of our proposed methodology
						on benchmark MNIST and Fashion-MNIST datasets and evaluate our
						strategy using appropriate quantitative metrics.
                    </p>


                    <div class="blockquote-1 bg-light p-4 ">
                        <blockquote class="blockquote">
                            <h4 class="mb-0">Progressive Clustering: An Unsupervised Approach Towards Continual Knowledge Acquisition of Incremental Data.</h4>
                            <footer class="blockquote-footer">3rd International Conference on Pattern Recognition and Artificial Intelligence. (Conference to be held in Paris, June 01).<cite title="Source Title"></cite></footer>
                            <div class="d-flex justify-content-end">
                                <!-- <button class="btn btn-primary"><i ><a class="h6" href="Deep_Visual_Attention_Based_Transfer_Clustering.pdf">View Paper</a></i></button> -->
                                <!-- <button class="btn btn-primary"><i ><a class="h6" href="Deep_Visual_Attention_Based_Transfer_Clustering.pdf">View Paper</a></i></button> -->
                                <div class="button_cont" text-align="center"><a class="example_a" href="https://dl.acm.org/doi/abs/10.1007/978-3-031-09282-4_30" target="_blank" rel="nofollow noopener">View Paper</a></div>
                                <div class="button_cont" text-align="center"><a class="example_a" href="https://docs.google.com/presentation/d/1SE_CbpKjpXlGwc4ylJxzTR1ApZzDWbs52K8pueBcf4Q/edit?usp=sharing" target="_blank" rel="nofollow noopener">View Slides</a></div>
                            
                            </div>
                        </blockquote>
                    </div>



                    <h2 class="h4">Keywords:</h2>
                    <ul>
                        <li>Unsupervised learning</li>
                        <li>Incremental data</li>
                        <li>Auto Encoders</li>
                        <li>Concept Drift</li>
                      </ul>


                    <p>
                        Many machine learning applications require learning algorithms to capture both
						spatial features and temporal behaviour in data. Existing algorithms lack ability
						to capture temporal dependencies in a natural, data-driven manner. Training a
						neural network also typically assumes that the data is non incremental in nature.
						However, in the real world, additional data accumulates gradually and the model
						requires training on the arrival of new data. To this end, Incremental Learning,
						a.k.a Continual Learning or Lifelong Learning, that learns from data arriving
						sequentially receives increasing attention. Dynamically growing data requires
						models preservation of previously learnt knowledge and acquire new knowledge.
                    </p>
					
                    <p>
						A widely studied setting in this field is image classification tasks, namely Class
						Incremental Learning (CIL), where the data of new classes arrive phase by
						phase. In CIL, the data of classes arrive phase by phase, resulting in the change
						of the data distribution, forcing the model to adapt to such changes in the data.
                    </p>
                    <h1 class="h2">A Brief Walkthrough</h1>
					<figure>
					<img src="./images/data_advent.png" class="bounce-little img-fluid shadow-sm rounded " alt="">
					<figcaption>Figure 1. - Different scenarios of data advent in real time applications..</figcaption>
					</figure>
                    <p style="text-align: justify;">
                        In CIL, a set of new classes needs to be learned in each phase, as depicted
						in Figure 1(middle row). The following three assumptions that exist in CIL are:
						(i) the number of classes across different phases is fixed; (ii) classes appearing
						in earlier phases will not appear in later phases again; (iii) training samples are
						well-balanced across different classes in each phase. However, these assumptions
						do not hold true in many real world applications. Towards this, we design an
						algorithm to generate data that has different number of classes in each phase
						with varied sample size for each class (Figure 1 bottom row). Towards such applications,
						where data accumulates dynamically, we demonstrate the learning
						process of dynamically growing data as shown in Figure 2. The data arriving is
						stored in data chunks d to learn and acquire its knowledge to memory(d). Acquisition
						of knowledge from currently availed data is a repetitive process adding
						to memory(D) which represents the knowledge acquired by the model LD over
						aggregate of all data D. Model learnt on previous data serves for learning a part
						d‘ of currently arrived data d. Concept drift has to be handled if existing over
						the stream of data to update the overall knowledge acquired by the model LD.
						We develop our proposed strategy Progressive Clustering in this fashion to train
						incremental data.
                    </p>
                    <br>
                    <p style="text-align: justify;">
                        Crowd-sourcing facilitates desired data at scale and involves task owners
						relying on a large batch of supposedly anonymous human resources with varying
						expertise contributing a diversified amount of data. In our case, we are interested
						in obtaining a large image corpus that is dynamically growing in nature. A
						pictorial representation of dynamically growing datasets where the increment
						is not merely in class, but also in the distribution of each class can be seen in
						Figure 1 (bottom row). In such scenarios, statistical properties of the cluster
						assignment, which the model is trying to predict may change over time. An
						essential step in this problem is to formulate an efficient categorization method
						that detects and updates such changes in data distribution. Towards this, we
						summarize our contributions as follows:
                    </p>
					
					<ul>
                        <li>We set up an environment that simulates the dynamically growing datasets, considering increments 
						with respect to class and in the distribution of each class.</li>
                        <li>We propose a novel strategy to handle the incremental nature of the data</li>
						<ul>
							<li>that clusters the current data chunk from antecedent models knowledge.</li>
							<li>that adapts to the change in the the behaviour of the data over time.</li>
							<li>to design deep dynamically growing models that adjust themselves with the 
							distribution of the dataset.</li>
						</ul>
                        <li>We show proposed strategy Progressive Clustering can be used as a plug-in in many 
						state-of-the-art techniques reducing the number of times the whole data has to be 
						re-clustered.</li>
                        <li>We experiment Progressive Clustering on a MNIST [10] and Fashion MNIST datasets 
						showing comparable results with the state-of-the-art methodologies that are proposed 
						towards clustering using consistent performance through various evaluation metrics.</li>
                    </ul>
					<figure>
					<img src="./images/overview.png" class="bounce-little img-fluid shadow-sm rounded " alt="">
					<figcaption>Figure 2. - Overview of Incremental Learning.</figcaption>
					</figure>


                    <h1 class="h2">Progressive CLustering</h1>
					<figure>
					<img src="./images/progressive_clustering.png" class="bounce-little img-fluid shadow-sm rounded " alt="">
					<figcaption>Figure 3. - Progressive Clustering.</figcaption>
					</figure>
                    <p style="text-align: justify;">
                        We propose a clustering strategy termed as Progressive Clustering that handles
						the dynamically growing datasets as shown Figure 3. Progressive clustering identifies
						the newly evolving clusters and updates the clusters as the newly availed
						data from current data chunks are added to previously identified clusters. The
						change in the data distribution is identified in to handle concept drift in the data
						stream. Algorithm 1 shows the incremental clustering of data using Progressive
						Clustering.
                    </p>


					<figure>
					<img src="./images/algorithm_1.png" alt="">
					</figure>

                    <h4>Incremental Data Generation for Progressive Clustering</h4>
                    <p style="text-align: justify;">
                        To simulate the environment of dynamically arriving data, we propose an algorithm
						that takes any image dataset as input and outputs a set of Data Chunks
						consisting of different number of samples from each class. Algorithm 2 limitations
						of CIL are alleviated by allowing classes to appear in a realistic manner
						across multiple phases. Specifically, we characterize each phase by the appearing
						classes and the number of samples appearing in each class. In our setting, these
						quantities are sampled from probabilistic distributions. Thus, different realistic
						scenarios can be simulated by varying these distributions. We use this setting
						of incremental data advent as the input to our proposed clustering algorithm,
						Progressive Clustering in absence of target variables.
                    </p>
					<figure>
					<img src="./images/algorithm_2.png" alt="">
					</figure>

					<h4>Latent Space Representation</h4>

                    <p style="text-align: justify;">
                        An autoencoder is used to encode the input image into a compressed and meaningful
						representation, and then decode it back such that the reconstructed image
						is similar as possible to the original one. These self-supervised architectures aim at 
						combining discriminative and representational properties by learning simultaneously an 
						encoder-generator map. An autoencoder, can be formally defined as a function
                    </p>

                    <h1 class="h2">Results</h1>
					<h4>Evaluation Methodology</h4>
					<p style="text-align: justify;">
					For the proposed strategy to categorize incremental data, we evaluate the performance
					of our model on each of the discrete modules. For evaluating Progressive
					Clustering, we use three standard unsupervised performance metrics i.e., ACC,
					NMI, and ARI. The labels assigned at the time of Progressive
					Clustering are used for training Deep Dynamic Incremental Classifier as the target
					variables. To evaluate the classifier, we use supervised accuracy (Accuracy).
					However, the overall performance of the the proposed strategy can be given
					by the ACC (Eq.11), which is calculated between the result of Deep Dynamic
					Incremental Classifier versus the original labels of the images.
					</p>

					<h4>Qualtitative Study</h4>
					<figure>
					<img src="./images/results.png" alt="">
					<figcaption class="table_caption">Table 1. - Results showing different quantitative metrics (average over 10 data chunks)
								depicting the performance of various clustering strategies on MNIST and Fashion
								MNIST datasets. It can be observed that the Progressive Clustering strategy can be
								used as a plug-in in many state-of-the-art techniques reducing the number of times the
								whole data has to be re-clustered.
					</figcaption>
					</figure>
                    <p style="text-align: justify;">
                        In this section, we discuss the effectiveness of our framework on MNIST and
						Fashion-MNIST datasets. We can find that our strategy Progressive Clustering
						attains comparable results with the state-of-the-art methodologies that are
						proposed for clustering. Table 1 shows that the proposed methodology achieves
						good results without re-clustering every data chunk on its arrival. It can be
						observed that algorithms defined in Section 3 can be plugged in to modify the
						state-of-the-art clustering methods to train the data in incremental fashion. The
						dataset is divided into the data chunks of 7000 images each, with varied number
						of images from each class in each data chunk. The CAE and SAE is pretrained
						end-to-end for 400 epochs, with the batch size of 256 using Adam optimizer with
						default parameters. The convergence threshold is set to 0.1%. Families of DEC
						are trained for 50, 000 iterations.
                    </p>

                    <h2 class = "h2">Conclusion</h2>


                    <p style="text-align: justify;">
                    In this paper, we proposed a categorization strategy to handle the incremental
					nature of the data by identifying concept drift in the data stream. Our method
					automatically discovers newly occurring object categories in unlabelled data and
					is used to train a classifier that can be used for various downstream tasks such as
					content based image retrieval systems, image data segregation etc. We proposed
					an algorithm to alleviate the problem of concept drift by designing progressive
					clustering algorithm capable of handling continually arriving data. We demonstrate
					our results on standard MNIST and Fashion-MNIST datasets to show
					our methodology shows comparable performance to state-of-the-art clustering
					algorithms which will have to be trained from scratch on the arrival of each
					data chunk. Deploying incremental learning algorithms for critical applications
					warrants circumspection and is still a work in progress and we believe our work
					is a step in this direction.
                    </p>
                </div>
                


                <h1 style="text-align: center;">Thank You</h1>

                <br><br><br>
                <footer role="contentinfo" class="footer">
                    <address style="text-align: center;">
                      Residential Address:<br>
                      Shri Nivas,<br>
                      H.No. 137, Akshay Colony,<br>
                      1st Phase, Gokul Road, <br>
                      Hubli, India, 580-030. <br>
                      </address>
                      
                
                
                  </footer>
                






            </div>
        </div>
    </div>

</div>
<!--end first-section-->

<!--footer-section-->
<div class="py-4 text-center bg-warning mt-5">
    <p class="m-0"> &copy; Copyright by Akshaykumar Gunari, all right reserved.</p>
</div>
<!--end footer section-->

<!-- Optional JavaScript -->
<!-- jQuery first, then Popper.js, then Bootstrap JS -->
<script src="https://code.jquery.com/jquery-3.4.1.slim.min.js" integrity="sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
</body>
</html>
